{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datalab ITAM - Proyecto de Transparencia de Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Objetivo:** extraer de datos de la [currícula y votaciones de la LXII legislatura](http://www.diputados.gob.mx/sistema_legislativo_LXII.html).\n",
    "<br><br> Como herramienta fundamental hacemos uso de la librería [`scrapy`](https://docs.scrapy.org/en/latest/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este proceso se divide en las siguientes secciones:\n",
    "1. [Definición del Spider](#Definición-del-Spider)\n",
    "<br/><br/>\n",
    "2. [Procesamiento de Datos](#Procesamiento-de-Datos)\n",
    "    * [Limpieza Perfil General](#Limpieza-Perfil-General)\n",
    "    * [Limpieza Proposiciones](#Limpieza-Proposiciones)\n",
    "    * [Limpieza Iniciativas](#Limpieza-Iniciativas)\n",
    "    * [Limpieza de la Ficha Curricular y las Comisiones](#Limpieza-de-la-Ficha-Curricular-y-las-Comisiones)\n",
    "    * [Limpieza Votaciones](#Limpieza-Votaciones)\n",
    "<br/><br/>\n",
    "3. [Ejecución del Spider](#Ejecución-del-Spider)\n",
    "<br/><br/>\n",
    "4. [Creación de la base de datos](#Creación-de-la-base-de-datos)\n",
    "<br/><br/>\n",
    "5. [Visualizando los datos](#Visualizando-los-datos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identificación de tablas\n",
    "A continuación se presenta un caso ejemplo señalando cada una de las tablas a las que haremos referencia más adelante\n",
    "\n",
    "**Perfil general:** La primera tabla por cada diputado corresponde a la siguiente sección de la currícula\n",
    "<img src=\"Parte162.jpg\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Iniciativas:** Podemos notar que, si bien tiene entradas con textos largos, no presenta una estructura muy compleja.\n",
    "<img src=\"ParteIniciativas62.jpg\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Proposiciones:** Notamos que es muy similar a la tabla de iniciativas, a diferencia de que contiene una columna extra\n",
    "<img src=\"ParteProposiciones62.jpg\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ficha Curricular:** Para cada una de los apartados dentro de la ficha (Escolaridad, Administación Pública, Trayectoria Política, ...) se genera una lista de diccionarios por separado\n",
    "<img src=\"ParteEscolaridad62.jpg\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tomando el [caso ejemplo](http://sitllxii.diputados.gob.mx/curricula.php?dipt=260), la información se guardará en el diccionario ***diccionario_final*** y abreviando las secciones de proposicones e iniciativas, la estructura dentro del archivo quedaría de la siguiente forma:\n",
    "```css\n",
    "{\n",
    "    \"glafirosalinasmendiola\": {\n",
    "        'PERFIL GENERAL': [\n",
    "            {\n",
    "                'ClaveUnica': 'glafirosalinasmendiola',\n",
    "                'Nombre': 'Glafiro Salinas Mendiola',\n",
    "                'TipoElección': 'Mayoría Relativa',\n",
    "                'Entidad': 'Tamaulipas',\n",
    "                'Partido': 'PAN',\n",
    "                'Distrito': '1',\n",
    "                'Curul': 'F-169',\n",
    "                'Correo': 'glafiro.salinas@congreso.gob.mx ',\n",
    "                'FechaNacimiento': '31-mayo',\n",
    "                'Suplente': 'Verónica Morales Huerta',\n",
    "                'UltimoGrado': 'Mayoría Relativa ',\n",
    "                'PaginaInternet': 'http://sitllxii.diputados.gob.mx/curricula.php?dipt=260'\n",
    "            }\n",
    "        ],\n",
    "        'COMISIONES': [\n",
    "            {\n",
    "                'Tipo': 'ORDINARIA',\n",
    "                'Comisión': ' Educación Pública y Servicios Educativos  '\n",
    "            },\n",
    "            ...\n",
    "        ],\n",
    "        \"INICIATIVAS\": [\n",
    "            {\n",
    "                'NombreIniciativa': 'Proyecto de decreto que reforma el artículo 3° de la Ley General de Salud.',\n",
    "                'TipoIniciativa': 'Adherente',\n",
    "                'FechaIniciativa': ' 2-Octubre-2012',\n",
    "                'TurnoComisionI': 'Salud ',\n",
    "                'SinopsisIniciativa': 'Incluir a la salud sexual ... ',\n",
    "                'TramiteIniciativa': 'Desechada 7-Marzo-2013 ',\n",
    "                'GacetaIniciativa': '2-Octubre-2012'\n",
    "            },...\n",
    "        ],\n",
    "        \"PROPOSICIONES\": [\n",
    "            {\n",
    "                'NombreProposicion': 'Punto de acuerdo por el que se crea la Comisión Especial de ...',\n",
    "                'TipoProposicion': 'Suscribe',\n",
    "                'FechaProposicion': ' 11-Septiembre-2012 ',\n",
    "                'TurnoComisionP': 'Junta de Coordinación Política ',\n",
    "                'ResolutivosProponente': 'PRIMERO.- Se crea la Comisión Especial de Aduanas ... \",\n",
    "                'ResolutivosAprobados': '.',\n",
    "                'TramiteProposicion': 'Desechada (art. 184, num 2)   15-Mayo-2013 ',\n",
    "                'GacetaProposicion': '11-Septiembre-2012'\n",
    "            },\n",
    "            ...\n",
    "        ],\n",
    "        \"ESCOLARIDAD\": [\n",
    "            {\n",
    "                'ESCOLARIDAD': 'Maestría - Administración de Empresas',\n",
    "                'Fechas': '1965-1970'\n",
    "            },\n",
    "            ...\n",
    "        ],\n",
    "        \"TRAYECTORIA POLÍTICA\": [\n",
    "            {\n",
    "                'TRAYECTORIA POLÍTICA': 'Coordinador Electoral - PAN',\n",
    "                'Fechas': '1998'\n",
    "            },\n",
    "            ...\n",
    "        ],\n",
    "        \"ADMINISTRACIÓN PÚBLICA LOCAL\": [\n",
    "            {\n",
    "                'ADMINISTRACIÓN PÚBLICA LOCAL': 'Catedrático - Facultad de Comercio y Administración de la ... ',\n",
    "                'Fechas': '1972-1980'\n",
    "            },\n",
    "            ...\n",
    "        ],\n",
    "        \"INICIATIVA PRIVADA\": [\n",
    "            {\n",
    "                'INICIATIVA PRIVADA': 'Gerente General - American FootWare, S.A.',\n",
    "                'Fechas': '1970-1980'\n",
    "            },\n",
    "            ...\n",
    "        ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Votaciones:** La estructura de las páginas que contienen las votaciones de cada diputado se muestra a continuación\n",
    "<img src=\"Votaciones62.jpg\" width=\"600\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Toda la información de votaciones se guardará en un diccionario llamado ***por_votaciones***, el cual tendrá esencialmente la siguiente estructura:\n",
    "\n",
    "```css\n",
    "{'ra3lgp':\n",
    "    {\n",
    "        'ClaveUnicaVotacion': 'ra3lgp',\n",
    "        'NombreVotacion': 'DECRETO QUE REFORMA EL ARTICULO 39 DE LA LOCGEUM (EN LO GENERAL Y EN LO PARTICULAR) ',\n",
    "        'FechaVotacion': '27 Septiembre 2012',\n",
    "        'mariaguadalupesanchezsantiago': 'A favor',\n",
    "        'germanpachecodiaz': 'A favor',\n",
    "        'josehumbertovegavazquez': 'Ausente',\n",
    "        'carlosalbertogarciagonzalez': 'Ausente',\n",
    "        'leopoldosanchezcruz': 'A favor',\n",
    "        'glafirosalinasmendiola': 'A favor',\n",
    "        'josealejandrollanasalba': 'A favor',\n",
    "        'rosalbadelacruzrequena': 'A favor',\n",
    "        'enriquecardenasdelavellano': 'A favor',\n",
    "        'marcelinaortacoronado': 'A favor',\n",
    "        ...\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "La key *'ra3lgp'* corresponde al identificador único de la votación. El value que corresponde a dicha key es un diccionario que contiene el nombre de la votación, su respectiva fecha y los sentidos de voto de cada uno de los diputados con respecto a dicha votación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importaciones necesarias:**\n",
    "- ***scrapy***\n",
    "- ***re***: será indispensable para la limpieza de textos\n",
    "- ***json***: la utilizaremos para la creación del archivo que contendrá la base de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy\n",
    "import numpy as np\n",
    "from scrapy.crawler import CrawlerProcess\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definición del Spider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Diputados(scrapy.Spider):\n",
    "    '''\n",
    "        En esta sección es donde se va hacer, principalmente, el trabajo de recolección de datos,\n",
    "        para su posterior procesamiento.\n",
    "    '''\n",
    "    name = \"spider_diputados\"\n",
    "    \n",
    "    def start_requests(self):\n",
    "        '''\n",
    "            Hacemos el llamado a cada una de las páginas que vamos a scrappear\n",
    "        '''\n",
    "        links = [urlCurr + i for i in terminaciones]\n",
    "        for link in links:\n",
    "            yield scrapy.Request( url = link, headers={'User-Agent': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:66.0) Gecko/20100101 Firefox/66.0'}, meta={'link':link},\n",
    "                              callback = self.parse )\n",
    "    \n",
    "    def parse(self,response):\n",
    "        '''\n",
    "            En esta sección primero obtenemos la información del Perfil General y la vamos guardando en un diccionario\n",
    "        '''\n",
    "        link = response.meta['link']\n",
    "        \n",
    "        # Información del Perfil General\n",
    "        nombre = response.css('span.Estilo67::text').extract_first()\n",
    "        nombre = limpiaText(nombre)\n",
    "        cumple = response.css('td.textoNegro::text').extract()[5]\n",
    "        curp = creaCurp(nombre)    # Generamos el identifiador único\n",
    "        dipus[curp]={}      # Declaramos el diccionario que contiene el Perfil General\n",
    "        dipus.get(curp,{})['ClaveUnica']=curp\n",
    "        dipus.get(curp,{})['Nombre']=nombre \n",
    "        dipus.get(curp,{})['TipoElección']=limpiaEsp(response.css('td.textoNegro::text').extract()[0])\n",
    "        dipus.get(curp,{})['Entidad']=limpiaEsp(response.css('td.textoNegro::text').extract()[1])\n",
    "        parti=response.xpath('//tr/td/table//td//img/@src').extract()[1]\n",
    "        dipus.get(curp,{})['Partido']=obtienePartido(parti)\n",
    "        dipus.get(curp,{})['Distrito']=limpiaEsp(response.css('td.textoNegro::text').extract()[2])\n",
    "        dipus.get(curp,{})['Curul'] =limpiaEsp(response.css('td.textoNegro::text').extract()[4])\n",
    "        dipus.get(curp,{})['Correo']=response.css('a.linkNegroSin::text').extract()[0]\n",
    "        dipus.get(curp,{})['FechaNacimiento']=limpiaEsp(cumple)\n",
    "        supl=response.css('span.Estilo67::text').extract()[6]\n",
    "        dipus.get(curp,{})['Suplente']=limpiaText(supl)\n",
    "        dipus.get(curp,{})['UltimoGrado']=response.xpath('//td[@class=\"textoNegro\"]/text()').extract_first()\n",
    "        dipus.get(curp,{})['PaginaInternet'] = link\n",
    "        \n",
    "        # Obtenemos la tabla de la ficha curricular sin procesar\n",
    "        exp_lista=response.css(\"table table td\").extract()\n",
    "        exp_lista=exp_lista[26:len(exp_lista)]\n",
    "        exp_texto = response.css(\"table table td::text\").extract()\n",
    "        dipus.get(curp,{})['BLABLA'] = exp_texto\n",
    "        exp_texto=exp_texto[11:len(exp_texto)]\n",
    "        \n",
    "        # Obtenemos la tabla de las comisiones sin procesar\n",
    "        comisiones = response.xpath(\"//td[contains(@align, 'left')]\").extract()[5]\n",
    "        \n",
    "        # Guardamos las 3 listas\n",
    "        dic_experiencia_lista[curp] = exp_lista\n",
    "        dic_experiencia_texto[curp] = exp_texto\n",
    "        dic_comisiones[curp] = comisiones\n",
    "        \n",
    "        # Obtenemos el link que nos redirige a la página que contiene los periodos ordinarios y extraordinarios\n",
    "        link_iniciativas=urlDipu + response.css('a.linkBlancoSin::attr(href)').extract()[0]\n",
    "        link_proposiciones=urlDipu + response.css('a.linkBlancoSin::attr(href)').extract()[1]\n",
    "        link_votaciones=urlDipu + response.css('a.linkBlancoSin::attr(href)').extract()[3]\n",
    "        \n",
    "        # Inicializamos los diccionarios donde vamos a guardar las proposiciones e iniciativas\n",
    "        dic_proposiciones[curp] = []\n",
    "        dic_iniciativas[curp]=[]\n",
    "        \n",
    "        # Mandamos el link de iniciativas recién obtenido \n",
    "        yield response.follow(url=link_iniciativas, headers={'User-Agent': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:66.0) Gecko/20100101 Firefox/66.0'},meta={'curp':curp},\n",
    "                              callback=self.parse6)\n",
    "        # Mandamos el link de proposiciones recién obtenido \n",
    "        yield response.follow(url=link_proposiciones, headers={'User-Agent': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:66.0) Gecko/20100101 Firefox/66.0'},meta={'curp':curp},\n",
    "                              callback=self.parse8)\n",
    "        # Mandamos el link de votaciones recién obtenido \n",
    "        yield response.follow(url=link_votaciones, headers={'User-Agent': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:66.0) Gecko/20100101 Firefox/66.0'},meta={'curp':curp},\n",
    "                              callback=self.parse4)\n",
    "    \n",
    "    def parse6(self,response):\n",
    "        '''\n",
    "            Dentro de esta sección se encuentran los links para cada uno de los periodos. Los guardamos y, uno por uno,\n",
    "            los visitamos para obtener las iniciativas de cada periodo.\n",
    "        '''\n",
    "        curp = response.meta['curp']\n",
    "        referencias = response.xpath('//a[@class=\"linkVerde\"]/@href').extract()\n",
    "        links = [urlDipu + referencia for referencia in referencias]\n",
    "        for li in links:\n",
    "            yield response.follow(url=li, headers={'User-Agent': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:66.0) Gecko/20100101 Firefox/66.0'},meta={'curp':curp},\n",
    "                              callback=self.parse7)\n",
    "    \n",
    "    def parse7(self,response):    \n",
    "        '''\n",
    "            En esta sección extraemos la tabla de iniciativas del periodo en el que nos encontremos\n",
    "        '''\n",
    "        curp = response.meta['curp']\n",
    "        listaInic = response.css('td.Estilo69').getall() # Obtenemos todas las entradas de la tabla\n",
    "        dic_iniciativas[curp] = dic_iniciativas[curp]+ listaInic # Guardamos las entradas con el resto de los periodos\n",
    "    \n",
    "    def parse8(self,response):\n",
    "        '''\n",
    "            Dentro de esta sección se encuentran los links para cada uno de los periodos. Los guardamos y, uno por uno,\n",
    "            los visitamos para obtener las proposiciones de cada periodo.\n",
    "        '''\n",
    "        curp = response.meta['curp']\n",
    "        referencias = response.xpath('//a[@class=\"linkVerde\"]/@href').extract()\n",
    "        links = [urlDipu + referencia for referencia in referencias]\n",
    "        for li in links:\n",
    "            yield response.follow(url=li, headers={'User-Agent': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:66.0) Gecko/20100101 Firefox/66.0'},meta={'curp':curp},\n",
    "                              callback=self.parse9)\n",
    "    \n",
    "    def parse9(self,response):    \n",
    "        '''\n",
    "            En esta sección extraemos la tabla de proposiciones del periodo en el que nos encontremos\n",
    "        '''\n",
    "        curp = response.meta['curp']\n",
    "        listaPropos = response.css('td.Estilo69').getall() # Obtenemos todas las entradas de la tabla\n",
    "        dic_proposiciones[curp]= dic_proposiciones[curp]+listaPropos # Guardamos las entradas con el resto de los periodos\n",
    "\n",
    "        \n",
    "    def parse4(self,response):\n",
    "        '''\n",
    "            Dentro de esta sección se encuentran los links para cada uno de los periodos. Los guardamos y, uno por uno,\n",
    "            los visitamos para obtener las votaciones de cada periodo.\n",
    "        '''\n",
    "        curp = response.meta['curp']\n",
    "        referencias = response.xpath('//a[@class=\"linkVerde\"]/@href').extract()\n",
    "        links = [urlDipu + referencia for referencia in referencias]\n",
    "        for li in links:\n",
    "            yield response.follow(url=li, headers={'User-Agent': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:66.0) Gecko/20100101 Firefox/66.0'},meta={'curp':curp},\n",
    "                              callback=self.parse5)\n",
    "                \n",
    "    def parse5(self,response):\n",
    "        '''\n",
    "            En esta sección obtendremos los sentidos del voto del periodo en cuestión.\n",
    "            El diccionario por_votaciones es el encargado de guardar en sus keys el identificador único de cada votación y \n",
    "            en sus values el diccionario que contiene el nombre de la votación, la fecha de la votación y el sentido del voto\n",
    "            de cada uno de los diputados con respecto a dicha votación.\n",
    "            La estructura de este diccionario por_votaciones es precisamente la mencionada en el ejemplo del principio del\n",
    "            documento.\n",
    "        '''\n",
    "        curp = response.meta['curp']\n",
    "        aux = response.xpath('//td[@class=\"smallVerde\"]/text()').extract()\n",
    "        todas_celdas=response.xpath('//td/text()').extract()[7:]\n",
    "        j=2; \n",
    "        fechaVotacion=todas_celdas[0] \n",
    "        for i in range(1,len(aux),4):\n",
    "            celda = todas_celdas[j] \n",
    "            votacion = response.xpath('//td[@class=\"smallVerde\"]/text()').extract()[i] # Extraemos el nombre de la votación\n",
    "            posi = response.xpath('//td[@class=\"smallVerde\"]/text()').extract()[i+2]   # Extraemos el sentido del voto del diputado\n",
    "            id_voto = limpiaVotacion(votacion)        # Obtenemos el identificador único de la votación\n",
    "            if(id_voto in por_votaciones.keys()): \n",
    "                por_votaciones[id_voto][curp]=posi   # Si la votación ya se encontraba registrada, únicamente guardamos el sentido del voto\n",
    "            else:       # Si la votación aún no se había registrado, guardamos tanto su nombre como su identificador único, así como el sentido del voto\n",
    "                por_votaciones[id_voto] = {\"ClaveUnicaVotacion\":id_voto,\"NombreVotacion\":votacion, \"FechaVotacion\": fechaVotacion, curp:posi}\n",
    "            if(i+4<len(aux)):       # Si encontramos una instancia de class = 'smallVerde', significa que las siguientes votaciones pertenecen a una nueva fecha\n",
    "                if(todas_celdas[j+4]!=response.xpath('//td[@class=\"smallVerde\"]/text()').extract()[i+4]): \n",
    "                    fechaVotacion=todas_celdas[j+3]  # cambiamos a la nueva fecha\n",
    "                    j=j+5 \n",
    "                else: \n",
    "                    j=j+4\n",
    "    \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procesamiento de Datos\n",
    "### Limpieza Perfil General"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creaCurp(nombre):\n",
    "    '''\n",
    "        Como identificador único de cada diputado tomamos su nombre en minúsculas, sin espacios, acentos o símbolos\n",
    "    '''\n",
    "    curp = nombre.replace('.', '')\n",
    "    curp = nombre.replace('-', '')\n",
    "    curp = curp.replace(' ', '')\n",
    "    curp = curp.replace('(DECESO)', '')\n",
    "    curp = curp.replace('(Deceso)', '')\n",
    "    curp = curp.lower()\n",
    "    curp = curp.replace('á', 'a')\n",
    "    curp = curp.replace('é', 'e')\n",
    "    curp = curp.replace('í', 'i')\n",
    "    curp = curp.replace('ó', 'o')\n",
    "    curp = curp.replace('ú', 'u')\n",
    "    #curp = curp.replace('ñ', 'n')\n",
    "    return curp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpiaText(nom):\n",
    "    '''\n",
    "        Esta función nos sirve para limpiar las información obtenida, quitando ciertas cadenas específicas\n",
    "    '''\n",
    "    resp = re.sub('\\s+',' ',nom)\n",
    "    resp = resp.replace('Dip. ', '')\n",
    "    resp = resp.replace('(LICENCIA)', '')\n",
    "    resp = resp.replace('Suplente: ', '')\n",
    "    resp = resp.replace('  ', ' ')\n",
    "    if(resp[-1]==\" \"):\n",
    "        resp = resp[0:len(resp)-1]    # Evita que nuestro string contenga un espacio al final\n",
    "    if(resp[0]==\" \"):\n",
    "        resp = resp[1:]               # Evita que nuestro string contenga un espacio al principio\n",
    "    return resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpiaEsp(nom):\n",
    "    '''\n",
    "        Similar a limpiaText, pero se enfoca únicamente en eliminar espacios innecesarios\n",
    "    '''\n",
    "    resp = re.sub('\\s+',' ',nom)\n",
    "    resp = resp.replace('  ', ' ')\n",
    "    if(resp!=\" \"):\n",
    "        if(resp[-1]==\" \"):\n",
    "            resp = resp[0:len(resp)-1]\n",
    "        if(resp[0]==\" \"):\n",
    "            resp = resp[1:]\n",
    "    return resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtienePartido(imagen):\n",
    "    '''\n",
    "        Dado que el sitio del que obtenemos los datos (sitl.diputados.gob.mx) no indica\n",
    "        el partido al que pertenece un diputado más que a través de una imagen, nos corresponde obtener dicho dato\n",
    "        por medio del nombre de la imagen correspondiente.\n",
    "        Esta función recibe el nombre de la imagen y devuelve en un string el partido del diputado.\n",
    "    '''\n",
    "    res=\"\"\n",
    "    if(imagen=='images/pan.png'):\n",
    "        res = \"PAN\"\n",
    "    elif(imagen=='images/logpt.jpg'):\n",
    "        res = \"PT\"\n",
    "    elif(imagen=='images/LogoMorena.jpg'):\n",
    "        res = \"Morena\"\n",
    "    elif(imagen=='images/encuentro.png'):\n",
    "        res = \"Encuentro Social\"\n",
    "    elif(imagen=='images/logo_movimiento_ciudadano.png'):\n",
    "        res = \"Movimiento Ciudadano\"\n",
    "    elif(imagen=='images/pri01.png'):\n",
    "        res = \"PRI\"\n",
    "    elif(imagen=='images/logvrd.jpg'):\n",
    "        res = \"Partido Verde\"\n",
    "    elif(imagen=='images/prd01.png'):\n",
    "        res = \"PRD\"\n",
    "    elif(imagen=='images/logo_SP.jpg'):\n",
    "        res = \"Sin Partido\"\n",
    "    elif(imagen==\"images/panal.gif\"):\n",
    "        res = \"Nueva Alianza\"\n",
    "    elif(imagen==\"images/independiente.png\"):\n",
    "        res = \"Independiente\"\n",
    "    else:\n",
    "         res = imagen\n",
    "    return res\n",
    "                                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpieza Proposiciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpiaPropos(listaProp):\n",
    "    '''\n",
    "        Esta función recibe la tabla de proposiciones obtenida por nuestro\n",
    "        Spider y se encarga de extaer la información de cada una de las 5 columnas.\n",
    "        Cada renglón de la corresponde a una proposición y de cada columna se extraen múltiples datos.\n",
    "        La 1a columna nos indica el nombre y tipo de la iniciativa (De grupo, proponente o Diversos Grupos Parlamentarios)\n",
    "        La 2a columna nos dan las comisiones en turno y la fecha de presentación.\n",
    "        La 3a columna nos da los resolutivos del proponente\n",
    "        La 4a columna los resolutivos aprobados\n",
    "        La 5a y última nos da el trámite en el que se encuentra la proposición y la fecha del mismo, así\n",
    "        como la fecha de publicación en Gaceta\n",
    "        Estos datos de cada proposición se guardan como diccionario, por lo que esta función devuelve\n",
    "        la tabla de proposiciones condensada en una lista de diccionarios.\n",
    "        Debido a la estructura tan diferente de cada una de las columnas, cada una requiere de su propio\n",
    "        proceso de limpieza de texto\n",
    "    '''\n",
    "    n=len(listaProp)\n",
    "    listaFinal=list()\n",
    "    for i in range(0,n,5):\n",
    "        renglon = listaProp[i:i+5]  # Seleccionamos las 5 columnas del renglón\n",
    "        \n",
    "        #Columna1\n",
    "        casilla = renglon[0]        # La primera entrada del renglón corresponde a la primera columna\n",
    "        resp = re.sub('\\s+',' ',casilla)\n",
    "        resp = resp.replace('<br>', '')\n",
    "        resp = resp.replace('</span>', '')\n",
    "        entrada=re.split('</b> |<span class=\"Estilo71\">',resp)\n",
    "        iniciativa=entrada[2]      # Extraemos el nombre de la proposición\n",
    "        tipo = re.split('<b>',entrada[3])[0].replace(': ','')  # Obtenemos el tipo de proposición\n",
    "                \n",
    "        #Columna2     \n",
    "        texto2=renglon[1]\n",
    "        listaProp2=texto2.split('<span class=\"Estilo71\">')\n",
    "        casilla2 = listaProp2[1]\n",
    "        resp2 = re.sub('\\s+',' ',casilla2)\n",
    "        resp2 = resp2.replace('<br>', '')\n",
    "        resp2 = resp2.replace('</span>', '')\n",
    "        resp2 = resp2.replace('</b>', '')\n",
    "        resp2 = resp2.replace('</td>', '')\n",
    "        entrada2=re.split('<b>',resp2)\n",
    "        fechaPres = entrada2[1]         # Obtenemos la fecha de presentación\n",
    "        if(2 in range(-len(entrada2), len(entrada2))):\n",
    "            clasif=entrada2[2].replace('- ', '')     # Obtenemos la comisión en turno\n",
    "        else:\n",
    "            clasif=\"NA\"      # No se especificó comisión en turno\n",
    "        \n",
    "        #Columna3\n",
    "        casilla3=renglon[2]\n",
    "        sinopsis = casilla3.replace('</td>', '')\n",
    "        sinopsis = sinopsis.replace('</span>', '')\n",
    "        sinopsis = sinopsis.replace('<br>', '')\n",
    "        sinopsis=sinopsis.split('<span class=\"Estilo71\">')[1]  # Obtenemos los resolutivos del proponente\n",
    "        \n",
    "        #Columna4\n",
    "        casilla4=renglon[3]\n",
    "        sinopsis2 = casilla4.replace('</td>', '')\n",
    "        sinopsis2 = sinopsis2.replace('</span>', '')\n",
    "        sinopsis2 = sinopsis2.replace('<br>', '')\n",
    "        sinopsis2=sinopsis2.split('<span class=\"Estilo71\">')[1]  # Obtenemos los resolutivos aprovados\n",
    "        \n",
    "        #Columna5\n",
    "        casilla5=renglon[4]\n",
    "        listaProp3=re.split('<span class=\"Estilo71\">',casilla5)  \n",
    "        resp3 = re.sub('\\s+',' ',listaProp3[1])\n",
    "        resp3 = resp3.replace('</td>', '')\n",
    "        resp3 = resp3.replace('</span>', '')\n",
    "        resp3 = resp3.replace(' </b>', '')\n",
    "        resp3 = resp3.replace('<br>', '')\n",
    "        status = resp3.replace('</a>', '')    \n",
    "        ultimo = re.split('</b>',status)[0].replace('<b>', '')\n",
    "\n",
    "        fecha_op = re.split('</b>',status)[1]\n",
    "        fecha_op = re.sub('\\s+',' ',fecha_op)\n",
    "        fecha_op = fecha_op.replace('</td>', '')\n",
    "        fecha_op = fecha_op.replace('</span>', '')\n",
    "        fecha_op = fecha_op.replace('<b>', '')\n",
    "        fecha_op = fecha_op.replace('<br>', '')\n",
    "        fecha_op = fecha_op.replace('</a>', '')\n",
    "        fecha_op = fecha_op.replace('con fecha', '')\n",
    "\n",
    "        tramite = ultimo + fecha_op # Obtenemos el trámite en el que se encuentra la proposición con su respectiva fecha\n",
    "\n",
    "        publicacion = listaProp3[2]  \n",
    "        pub_final=re.split('<b>',publicacion)[1]\n",
    "        pub_final = pub_final.replace('</td>', '')\n",
    "        pub_final = pub_final.replace('</span>', '')\n",
    "        pub_final = pub_final.replace('</b>', '')\n",
    "        pub_final = pub_final.replace('<br>', '')\n",
    "        pub_final = pub_final.replace('</a>', '')  # Extraemos la fecha de publicación\n",
    "\n",
    "        listaFinal.append({\"NombreProposicion\": iniciativa,\"TipoProposicion\": tipo,\"FechaProposicion\":fechaPres,\"TurnoComisionP\":clasif,\"ResolutivosProponente\":sinopsis,\"ResolutivosAprobados\":sinopsis2,\"TramiteProposicion\":tramite, \"GacetaProposicion\":pub_final})\n",
    "    return listaFinal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpieza Iniciativas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpiaInici(listaProp):\n",
    "    '''\n",
    "        Esta función recibe la tabla de iniciativas obtenida por nuestro\n",
    "        Spider y se encarga de extaer la información de cada una de las 4 columnas.\n",
    "        Cada renglón de la corresponde a una iniciativa y de cada columna se extraen múltiples datos.\n",
    "        La 1a columna nos indica el nombre y tipo de la iniciativa (De grupo, proponente o Diversos Grupos Parlamentarios)\n",
    "        La 2a columna nos dan las comisiones en turno y la fecha de presentación.\n",
    "        La 3a columna nos da la sinopsis\n",
    "        La 4a y última nos da el trámite en el pleno y la fecha del mismo, así como la fecha de publicación en Gaceta\n",
    "        Estos datos de cada iniciativa se guardan como diccionario, por lo que esta función devuelve la \n",
    "        tabla de iniciativas condensada en una lista de diccionarios.\n",
    "        Debido a la estructura tan diferente de cada una de las columnas, cada una requiere de su propio\n",
    "        proceso de limpieza de texto\n",
    "    '''\n",
    "    n=len(listaProp)\n",
    "    listaFinal=list()\n",
    "    for i in range(0,n,4):\n",
    "        renglon = listaProp[i:i+4] # Seleccionamos las 4 columnas del renglón\n",
    "        #Columna1\n",
    "        casilla = renglon[0]     # La primera entrada del renglón corresponde a la primera columna\n",
    "        resp = re.sub('\\s+',' ',casilla)\n",
    "        resp = resp.replace('<br>', '')\n",
    "        resp = resp.replace('</span>', '')\n",
    "        entrada=re.split('</b> |<span class=\"Estilo71\">',resp)\n",
    "        iniciativa=entrada[2]        # Extraemos el nombre de la proposición\n",
    "        tipo = re.split('<b>',entrada[3])[0].replace(': ','')   # Obtenemos el tipo de proposición\n",
    "        \n",
    "        #Columna2\n",
    "        texto2=renglon[1]\n",
    "        listaProp2=texto2.split('</span>')\n",
    "        casilla2 = listaProp2[0]#\n",
    "        resp2 = re.sub('\\s+',' ',casilla2)\n",
    "        resp2 = resp2.replace('<br>', '')\n",
    "        resp2 = resp2.replace('<span class=\"Estilo71\">', '')\n",
    "        resp2 = resp2.replace('</b>', '')\n",
    "        resp2 = resp2.replace('</td>', '')\n",
    "        entrada2=re.split('<b>',resp2)\n",
    "        fechaPres = entrada2[1]     # Obtenemos la fecha de presentación\n",
    "\n",
    "        resp3 = re.sub('\\s+',' ',listaProp2[1])\n",
    "        resp3 = resp3.replace('<br>', '')\n",
    "        resp3 = resp3.replace('<span class=\"Estilo71\">', '')\n",
    "        resp3 = resp3.replace('</b>', '')\n",
    "        resp3 = resp3.replace('</td>', '')\n",
    "        entrada3=resp3.replace('<b>','')\n",
    "        if(entrada3[0]==' ' and entrada3[1]=='-' and entrada3[2]==' '):\n",
    "            entrada3=entrada3[3:]\n",
    "        clasif=entrada3      # Obtenemos la comisión en turno  \n",
    "        \n",
    "        \n",
    "        #Columna3\n",
    "        casilla3=renglon[2]\n",
    "        sinopsis = casilla3.replace('</td>', '')\n",
    "        sinopsis = sinopsis.replace('</span>', '')\n",
    "        sinopsis=sinopsis.split('<span class=\"Estilo71\">')[1]  # Obtenemos la sinopsis\n",
    "        \n",
    "        #Columna4\n",
    "        casilla4=renglon[3]\n",
    "        listaProp3=re.split('<b>',casilla4)\n",
    "        resp3 = re.sub('\\s+',' ',listaProp3[2])\n",
    "        resp3 = resp3.replace('</td>', '')\n",
    "        resp3 = resp3.replace('</span>', '')\n",
    "        resp3 = resp3.replace('</b>', '')\n",
    "        publicacion = resp3.replace('</a>', '')   # Obtenemos la fecha de publicación\n",
    "        \n",
    "        parte1 = re.split('</span>',listaProp3[1])\n",
    "        parte1 = re.sub('</b>',' ', parte1[0])\n",
    "        status = re.sub('<br>  con fecha','',parte1)\n",
    "        status = re.sub('\\s+',' ',status)\n",
    "        \n",
    "        \n",
    "        if 'linkTitulo\">' in status:   # Por si la fecha viene con link\n",
    "            status = re.sub('</a>','',status)\n",
    "            status = re.sub(' [<>].*[<>]','',status)\n",
    "        \n",
    "        tramite = status    # Obtenemos el trámite en el pleno con su respectiva fecha\n",
    "        \n",
    "        listaFinal.append({\"NombreIniciativa\": iniciativa,\"TipoIniciativa\": tipo,\"FechaIniciativa\":fechaPres,\"TurnoComisionI\":clasif,\"SinopsisIniciativa\":sinopsis,\"TramiteIniciativa\":tramite, \"GacetaIniciativa\":publicacion})\n",
    "    return listaFinal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpieza de la Ficha Curricular y las Comisiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtieneComi(li):\n",
    "    '''\n",
    "        El listado de comisiones a las que pertenece un diputado proviene de una tabla independiente\n",
    "        de aquella que contiene el perfil básico y aquella que contiene la ficha curricular. Esta función \n",
    "        recibe como único atributo la tabla de comisiones y se encarga de extraer el nombre de la comisión \n",
    "        y el tipo de la misma (Ordinaria, Grupo de Amistad, ...).\n",
    "        Cada comisión se guarda en un diccionario, por lo que la función tiene como salida una lista de\n",
    "        diccionarios.\n",
    "    '''\n",
    "    apartado=\"\"\n",
    "    comi=list()\n",
    "    i=0\n",
    "    while(i<len(li)-1):\n",
    "        if 'span class=\"Estilo67\">' in li[i]:    # Este 'Estilo67' nos indica cuando se encuentra el tipo de comisión\n",
    "            s=li[i].split('\"Estilo67\">')\n",
    "            apartado=s[1]               # Obtenemos el tipo\n",
    "            i=i+1\n",
    "        elif 'class=\"linkNegroSin\">' in li[i]:   # Este 'linkNegroSin' nos indica cuando se encuentra el nombre de la comisión\n",
    "            t=li[i].split('\"linkNegroSin\">')\n",
    "            texto = t[1]                # Obtenemos el nombre\n",
    "            comi.append({\"Tipo\":apartado,\"Comisión\":texto})\n",
    "            i=i+1\n",
    "        else:\n",
    "            i=i+1\n",
    "    return comi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def empataLis(li1,li2):\n",
    "    '''\n",
    "        Debido a la forma en la que la tabla de ficha curricular está estructurada, los datos faltantes crean\n",
    "        un problema al querer organizar la información de la tabla. Esta función tiene como único objetivo rellenar\n",
    "        los espacios en los que faltan datos con la notación 'NA', para que la estructura de la tabla se mantenga consistente\n",
    "        y sea manejable en las siguientes partes del proceso'\n",
    "    '''\n",
    "    if(len(li1)!=len(li2)):\n",
    "        for i in range(0,len(li1)):\n",
    "            if '\"></td>' in li1[i]: # Cuando hay un dato faltante, el código HTML no contiene texto y hace un salto de celda\n",
    "                li2.insert(i, \"NA\") # por lo que rellenamos con la notación NA para evitar dicho salto de celda.\n",
    "                if(len(li1)==len(li2)):\n",
    "                    break\n",
    "    return li2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtieneExp(curp,li1,li2,tabla_comi, liInic,liPropos,perfil_general):\n",
    "    '''\n",
    "        Esta función es la encargada de juntar toda la información de un diputado y guardarla en un diccionario.\n",
    "        \n",
    "        liInic y liPropos son las tablas de iniciativas y proposiciones, respectivamente. Se limpiarán y guardarán en listas\n",
    "        de diccionarios por medio de las funciones limpiaInici y limpiaPropos antes declaradas.\n",
    "        \n",
    "        tabla_comi es la lista de comisiones sin procesar. Por medio de la función obtieneComi, se adquiere la lista de\n",
    "        diccionarios con cada una de las comisiones\n",
    "        \n",
    "        perfil_general es el diccionario con la información básica ya obtenida. Este diccionario ya no requiere de mayor\n",
    "        procesamiento.\n",
    "        \n",
    "        Los argumentos de entrada li1 y li2 proporcionarán la información de la ficha curricular con la ayuda de la\n",
    "        función empataLis vista anteriormente.\n",
    "        Para cada apartado de la ficha curricular (Escolaridad, Experiencia Legislativa, Trayectoria Política, ...) se genera\n",
    "        una lista de diccionarios, donde cada diccionario es una entrada de cada apartado.\n",
    "        \n",
    "        Esta función devuelve un diccionario por diputado cuyas keys son los nombres de las tablas a guardar,\n",
    "        los valores son sus respectivas listas de diccionarios. La estructura del diccionario de salida es precisamente la\n",
    "        mencionada en el ejemplo al principio del documento.\n",
    "    '''\n",
    "    exp={\"CURP\":curp}\n",
    "    exp={\"PERFIL GENERAL\":[perfil_general]}  # Empezamos guardando el perfil general\n",
    "    tabla_comi_sep = tabla_comi.split(\"</\")\n",
    "    list_comis=obtieneComi(tabla_comi_sep)   # Procesamos la tabla de comisiones\n",
    "    if list_comis!=[]:\n",
    "        exp[\"COMISIONES\"]=list_comis    # Guardamos las comisiones, si existen\n",
    "    inics = limpiaInici(liInic)     # Procesamos la tabla de iniciativas\n",
    "    props = limpiaPropos(liPropos)  # Procesamos la tabla de proposiciones\n",
    "    exp[\"INICIATIVAS\"]=inics        # Guardamos las iniciativas\n",
    "    exp[\"PROPOSICIONES\"]=props      # Guardamos las proposiciones\n",
    "    \n",
    "    if(len(list_comis)!=0):\n",
    "        x = set()\n",
    "        for i in list_comis:\n",
    "            tip= i['Tipo']\n",
    "            x.add(tip)\n",
    "        numTipos = len(x)-1\n",
    "        li2 = li2[1+2*numTipos + len(list_comis):]\n",
    "    \n",
    "    li2=empataLis(li1,li2)    # Comenzamos a procesar la ficha curricular\n",
    "    \n",
    "    apartado=\"\"\n",
    "    i=0\n",
    "    while(i<len(li1)):\n",
    "        if 'class=\"TitulosVerde\"' in li1[i] and i+3<len(li1): # 'TitulosVerde' nos indica el comienzo de un\n",
    "            if li2[i+1]!='NA' and li2[i+1]!='.':              #  nuevo apartado de la ficha curricular\n",
    "                apartado=li2[i]\n",
    "                nom = apartado + \"\"\n",
    "                exp[apartado]=[{nom:li2[i+1] + \" - \" + li2[i+2],\"Fechas\":li2[i+3]}] # Guardamos la experiencia con sus fechas\n",
    "            i=i+4\n",
    "        elif 'class=\"textoNegro\"' in li1[i]:                  # 'textoNegro' nos indica que seguimos en el mismo apartado\n",
    "            nom = apartado + \"\"\n",
    "            exp[apartado].append({nom:li2[i] + \" - \" + li2[i+1],\"Fechas\":li2[i+2]}) # Guardamos la experiencia con sus fechas\n",
    "            i=i+3\n",
    "    return exp          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpieza Votaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpiaVotacion(nombreVot):\n",
    "    '''\n",
    "        El propósito de esta función es generar un identificador único para cada una de las votaciones.\n",
    "        En primer lugar, se limpia el texto eliminando algunas de las palabras más comunes. Posteriormente, \n",
    "        se eliminan signos de puntuación y se convierte todo el texto a minúsculas. Por último, se genera el identificador\n",
    "        con la primera letra de cada palabra.\n",
    "    '''\n",
    "    nombreVot = nombreVot.replace('(', '')\n",
    "    nombreVot = nombreVot.replace(')', '')\n",
    "    nombreVot = nombreVot.replace(' SE ', ' ')\n",
    "    nombreVot = nombreVot.replace('DECRETO', '')\n",
    "    nombreVot = nombreVot.replace(' QUE ', ' ')\n",
    "    nombreVot = nombreVot.replace(' SE ', ' ')\n",
    "    nombreVot = nombreVot.replace(' DE ', ' ')\n",
    "    nombreVot = nombreVot.replace(' A ', ' ')\n",
    "    nombreVot = nombreVot.replace(' LA ', ' ')\n",
    "    nombreVot = nombreVot.replace(' EL ', ' ')\n",
    "    nombreVot = nombreVot.replace(' POR ', ' ')\n",
    "    nombreVot = nombreVot.replace(' PARA ', ' ')\n",
    "    nombreVot = nombreVot.replace(' LOS ', ' ')\n",
    "    nombreVot = nombreVot.replace(' LAS ', ' ')\n",
    "    nombreVot = nombreVot.replace(' Y ', ' ')\n",
    "    nombreVot = nombreVot.replace(' E ', ' ')\n",
    "    nombreVot = nombreVot.replace(' CON ', ' ')\n",
    "    nombreVot = nombreVot.replace(' LEY ', ' ')\n",
    "    nombreVot = nombreVot.replace(' EN ', ' ')\n",
    "    nombreVot = nombreVot.replace(' LO ', ' ')\n",
    "    nombreVot = nombreVot.replace(' DEL ', ' ')\n",
    "    nombreVot = nombreVot.replace('Á', 'A')\n",
    "    nombreVot = nombreVot.replace('É', 'E')\n",
    "    nombreVot = nombreVot.replace('Í', 'I')\n",
    "    nombreVot = nombreVot.replace('Ó', 'O')\n",
    "    nombreVot = nombreVot.replace('Ú', 'U')\n",
    "    nombreVot = nombreVot.replace('.', ' ')\n",
    "    nombreVot = nombreVot.replace(';', ' ')\n",
    "    nombreVot = nombreVot.replace(',', ' ')\n",
    "    nombreVot = nombreVot.replace('  ', ' ')\n",
    "    nombreVot = nombreVot.lower()\n",
    "    nombreFin=\"\"\n",
    "    for s in nombreVot.split():\n",
    "        nombreFin+=s[0]\n",
    "    return nombreFin    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejecución del Spider\n",
    "\n",
    "Es aquí donde, después de declarar el Spider y las funciones de limpieza y procesamiento de datos, se echa a correr todo el proceso. Declaramos los 3 diccionarios que contendrán las bases de datos.\n",
    "\n",
    "* *dipus* contendrá todos los perfiles básicos\n",
    "* *por_votaciones* contará con todas las votaciones\n",
    "* *diccionario_final* será el diccionario que contendrá los perfiles básicos y además las iniciativas, proposiciones, fichas curriculares y comisiones de todos los diputados. Este diccionario se crea después de la ejecución del spider a partir de la información contenida en *dic_proposiciones*, *dic_iniciativas*, *dic_experiencia_lista*, *dic_experiencia_texto* y *dic_comisiones*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-13 14:55:29 [scrapy.utils.log] INFO: Scrapy 2.4.1 started (bot: scrapybot)\n",
      "2021-05-13 14:55:29 [scrapy.utils.log] INFO: Versions: lxml 4.6.2.0, libxml2 2.9.5, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 21.2.0, Python 3.8.2 (tags/v3.8.2:7b3ab59, Feb 25 2020, 23:03:10) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 20.0.1 (OpenSSL 1.1.1j  16 Feb 2021), cryptography 3.4.6, Platform Windows-10-10.0.19041-SP0\n",
      "2021-05-13 14:55:29 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor\n",
      "2021-05-13 14:55:29 [scrapy.crawler] INFO: Overridden settings:\n",
      "{}\n",
      "2021-05-13 14:55:29 [scrapy.extensions.telnet] INFO: Telnet Password: 946a10fe1a6886e1\n",
      "2021-05-13 14:55:29 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2021-05-13 14:55:30 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2021-05-13 14:55:30 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2021-05-13 14:55:30 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2021-05-13 14:55:30 [scrapy.core.engine] INFO: Spider opened\n",
      "2021-05-13 14:55:30 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2021-05-13 14:55:30 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023\n",
      "2021-05-13 14:55:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://sitllxii.diputados.gob.mx/curricula.php?dipt=307> (referer: None)\n",
      "2021-05-13 14:55:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://sitllxii.diputados.gob.mx/curricula.php?dipt=304> (referer: None)\n",
      "2021-05-13 14:55:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://sitllxii.diputados.gob.mx/curricula.php?dipt=316> (referer: None)\n",
      "2021-05-13 14:55:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://sitllxii.diputados.gob.mx/iniciativas_diputados_xperiodonplxii.php?dipt=307> (referer: http://sitllxii.diputados.gob.mx/curricula.php?dipt=307)\n",
      "2021-05-13 14:55:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://sitllxii.diputados.gob.mx/iniciativas_diputados_xperiodonplxii.php?dipt=304> (referer: http://sitllxii.diputados.gob.mx/curricula.php?dipt=304)\n",
      "2021-05-13 14:55:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://sitllxii.diputados.gob.mx/votaciones_diputados_xperiodonplxii.php?dipt=304> (referer: http://sitllxii.diputados.gob.mx/curricula.php?dipt=304)\n",
      "2021-05-13 14:55:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://sitllxii.diputados.gob.mx/proposiciones_diputados_xperiodonplxii.php?dipt=307> (referer: http://sitllxii.diputados.gob.mx/curricula.php?dipt=307)\n",
      "2021-05-13 14:55:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://sitllxii.diputados.gob.mx/iniciativas_diputados_xperiodonplxii.php?dipt=316> (referer: http://sitllxii.diputados.gob.mx/curricula.php?dipt=316)\n",
      "2021-05-13 14:55:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://sitllxii.diputados.gob.mx/proposiciones_diputados_xperiodonplxii.php?dipt=304> (referer: http://sitllxii.diputados.gob.mx/curricula.php?dipt=304)\n",
      "2021-05-13 14:55:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://sitllxii.diputados.gob.mx/votaciones_diputados_xperiodonplxii.php?dipt=307> (referer: http://sitllxii.diputados.gob.mx/curricula.php?dipt=307)\n",
      "2021-05-13 14:55:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://sitllxii.diputados.gob.mx/proposiciones_diputados_xperiodonplxii.php?dipt=316> (referer: http://sitllxii.diputados.gob.mx/curricula.php?dipt=316)\n",
      "2021-05-13 14:55:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://sitllxii.diputados.gob.mx/votaciones_diputados_xperiodonplxii.php?dipt=316> (referer: http://sitllxii.diputados.gob.mx/curricula.php?dipt=316)\n",
      "2021-05-13 14:55:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://sitllxii.diputados.gob.mx/iniciativas_por_pernplxii.php?iddipt=307&pert=7> (referer: http://sitllxii.diputados.gob.mx/iniciativas_diputados_xperiodonplxii.php?dipt=307)\n",
      "2021-05-13 14:55:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://sitllxii.diputados.gob.mx/iniciativas_por_pernplxii.php?iddipt=307&pert=12> (referer: http://sitllxii.diputados.gob.mx/iniciativas_diputados_xperiodonplxii.php?dipt=307)\n",
      "2021-05-13 14:55:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://sitllxii.diputados.gob.mx/iniciativas_por_pernplxii.php?iddipt=307&pert=9> (referer: http://sitllxii.diputados.gob.mx/iniciativas_diputados_xperiodonplxii.php?dipt=307)\n",
      "2021-05-13 14:55:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://sitllxii.diputados.gob.mx/iniciativas_por_pernplxii.php?iddipt=307&pert=11> (referer: http://sitllxii.diputados.gob.mx/iniciativas_diputados_xperiodonplxii.php?dipt=307)\n",
      "2021-05-13 14:55:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://sitllxii.diputados.gob.mx/iniciativas_por_pernplxii.php?iddipt=307&pert=3> (referer: http://sitllxii.diputados.gob.mx/iniciativas_diputados_xperiodonplxii.php?dipt=307)\n",
      "2021-05-13 14:55:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://sitllxii.diputados.gob.mx/iniciativas_por_pernplxii.php?iddipt=307&pert=5> (referer: http://sitllxii.diputados.gob.mx/iniciativas_diputados_xperiodonplxii.php?dipt=307)\n",
      "2021-05-13 14:55:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://sitllxii.diputados.gob.mx/iniciativas_por_pernplxii.php?iddipt=307&pert=1> (referer: http://sitllxii.diputados.gob.mx/iniciativas_diputados_xperiodonplxii.php?dipt=307)\n",
      "2021-05-13 14:55:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://sitllxii.diputados.gob.mx/iniciativas_por_pernplxii.php?iddipt=304&pert=11> (referer: http://sitllxii.diputados.gob.mx/iniciativas_diputados_xperiodonplxii.php?dipt=304)\n",
      "2021-05-13 14:55:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://sitllxii.diputados.gob.mx/curricula.php?dipt=302> (referer: None)\n",
      "2021-05-13 14:55:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://sitllxii.diputados.gob.mx/iniciativas_por_pernplxii.php?iddipt=304&pert=6> (referer: http://sitllxii.diputados.gob.mx/iniciativas_diputados_xperiodonplxii.php?dipt=304)\n",
      "2021-05-13 14:55:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://sitllxii.diputados.gob.mx/iniciativas_por_pernplxii.php?iddipt=304&pert=7> (referer: http://sitllxii.diputados.gob.mx/iniciativas_diputados_xperiodonplxii.php?dipt=304)\n",
      "2021-05-13 14:55:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://sitllxii.diputados.gob.mx/iniciativas_por_pernplxii.php?iddipt=304&pert=9> (referer: http://sitllxii.diputados.gob.mx/iniciativas_diputados_xperiodonplxii.php?dipt=304)\n",
      "2021-05-13 14:55:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://sitllxii.diputados.gob.mx/iniciativas_por_pernplxii.php?iddipt=304&pert=3> (referer: http://sitllxii.diputados.gob.mx/iniciativas_diputados_xperiodonplxii.php?dipt=304)\n",
      "2021-05-13 14:55:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://sitllxii.diputados.gob.mx/iniciativas_por_pernplxii.php?iddipt=304&pert=1> (referer: http://sitllxii.diputados.gob.mx/iniciativas_diputados_xperiodonplxii.php?dipt=304)\n",
      "2021-05-13 14:55:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://sitllxii.diputados.gob.mx/votaciones_por_pernplxii.php?iddipt=316&pert=18> (referer: http://sitllxii.diputados.gob.mx/votaciones_diputados_xperiodonplxii.php?dipt=316)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-13 14:55:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://sitllxii.diputados.gob.mx/votaciones_por_pernplxii.php?iddipt=316&pert=17> (referer: http://sitllxii.diputados.gob.mx/votaciones_diputados_xperiodonplxii.php?dipt=316)\n",
      "2021-05-13 14:55:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://sitllxii.diputados.gob.mx/votaciones_por_pernplxii.php?iddipt=304&pert=11> (referer: http://sitllxii.diputados.gob.mx/votaciones_diputados_xperiodonplxii.php?dipt=304)\n",
      "2021-05-13 14:55:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://sitllxii.diputados.gob.mx/votaciones_por_pernplxii.php?iddipt=316&pert=16> (referer: http://sitllxii.diputados.gob.mx/votaciones_diputados_xperiodonplxii.php?dipt=316)\n",
      "2021-05-13 14:55:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://sitllxii.diputados.gob.mx/votaciones_por_pernplxii.php?iddipt=316&pert=11> (referer: http://sitllxii.diputados.gob.mx/votaciones_diputados_xperiodonplxii.php?dipt=316)\n",
      "2021-05-13 14:55:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://sitllxii.diputados.gob.mx/votaciones_por_pernplxii.php?iddipt=316&pert=15> (referer: http://sitllxii.diputados.gob.mx/votaciones_diputados_xperiodonplxii.php?dipt=316)\n",
      "2021-05-13 14:55:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://sitllxii.diputados.gob.mx/iniciativas_por_pernplxii.php?iddipt=304&pert=5> (referer: http://sitllxii.diputados.gob.mx/iniciativas_diputados_xperiodonplxii.php?dipt=304)\n",
      "2021-05-13 14:55:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://sitllxii.diputados.gob.mx/votaciones_por_pernplxii.php?iddipt=316&pert=9> (referer: http://sitllxii.diputados.gob.mx/votaciones_diputados_xperiodonplxii.php?dipt=316)\n",
      "2021-05-13 14:55:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://sitllxii.diputados.gob.mx/votaciones_por_pernplxii.php?iddipt=316&pert=13> (referer: http://sitllxii.diputados.gob.mx/votaciones_diputados_xperiodonplxii.php?dipt=316)\n",
      "2021-05-13 14:55:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://sitllxii.diputados.gob.mx/votaciones_por_pernplxii.php?iddipt=316&pert=14> (referer: http://sitllxii.diputados.gob.mx/votaciones_diputados_xperiodonplxii.php?dipt=316)\n",
      "2021-05-13 14:55:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://sitllxii.diputados.gob.mx/proposiciones_por_pernplxii.php?iddipt=316&pert=10> (referer: http://sitllxii.diputados.gob.mx/proposiciones_diputados_xperiodonplxii.php?dipt=316)\n",
      "2021-05-13 14:55:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://sitllxii.diputados.gob.mx/votaciones_por_pernplxii.php?iddipt=316&pert=1> (referer: http://sitllxii.diputados.gob.mx/votaciones_diputados_xperiodonplxii.php?dipt=316)\n",
      "2021-05-13 14:55:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://sitllxii.diputados.gob.mx/iniciativas_diputados_xperiodonplxii.php?dipt=302> (referer: http://sitllxii.diputados.gob.mx/curricula.php?dipt=302)\n",
      "2021-05-13 14:55:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://sitllxii.diputados.gob.mx/votaciones_por_pernplxii.php?iddipt=316&pert=5> (referer: http://sitllxii.diputados.gob.mx/votaciones_diputados_xperiodonplxii.php?dipt=316)\n",
      "2021-05-13 14:55:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://sitllxii.diputados.gob.mx/votaciones_por_pernplxii.php?iddipt=316&pert=7> (referer: http://sitllxii.diputados.gob.mx/votaciones_diputados_xperiodonplxii.php?dipt=316)\n",
      "2021-05-13 14:55:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://sitllxii.diputados.gob.mx/votaciones_por_pernplxii.php?iddipt=316&pert=3> (referer: http://sitllxii.diputados.gob.mx/votaciones_diputados_xperiodonplxii.php?dipt=316)\n",
      "2021-05-13 14:55:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://sitllxii.diputados.gob.mx/votaciones_diputados_xperiodonplxii.php?dipt=302> (referer: http://sitllxii.diputados.gob.mx/curricula.php?dipt=302)\n",
      "2021-05-13 14:55:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://sitllxii.diputados.gob.mx/proposiciones_por_pernplxii.php?iddipt=316&pert=7> (referer: http://sitllxii.diputados.gob.mx/proposiciones_diputados_xperiodonplxii.php?dipt=316)\n",
      "2021-05-13 14:55:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://sitllxii.diputados.gob.mx/votaciones_por_pernplxii.php?iddipt=307&pert=17> (referer: http://sitllxii.diputados.gob.mx/votaciones_diputados_xperiodonplxii.php?dipt=307)\n",
      "2021-05-13 14:55:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://sitllxii.diputados.gob.mx/proposiciones_por_pernplxii.php?iddipt=316&pert=1> (referer: http://sitllxii.diputados.gob.mx/proposiciones_diputados_xperiodonplxii.php?dipt=316)\n",
      "2021-05-13 14:55:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://sitllxii.diputados.gob.mx/proposiciones_diputados_xperiodonplxii.php?dipt=302> (referer: http://sitllxii.diputados.gob.mx/curricula.php?dipt=302)\n",
      "2021-05-13 14:55:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://sitllxii.diputados.gob.mx/votaciones_por_pernplxii.php?iddipt=307&pert=11> (referer: http://sitllxii.diputados.gob.mx/votaciones_diputados_xperiodonplxii.php?dipt=307)\n",
      "2021-05-13 14:55:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://sitllxii.diputados.gob.mx/votaciones_por_pernplxii.php?iddipt=307&pert=18> (referer: http://sitllxii.diputados.gob.mx/votaciones_diputados_xperiodonplxii.php?dipt=307)\n",
      "2021-05-13 14:55:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://sitllxii.diputados.gob.mx/votaciones_por_pernplxii.php?iddipt=307&pert=9> (referer: http://sitllxii.diputados.gob.mx/votaciones_diputados_xperiodonplxii.php?dipt=307)\n",
      "2021-05-13 14:55:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://sitllxii.diputados.gob.mx/votaciones_por_pernplxii.php?iddipt=307&pert=16> (referer: http://sitllxii.diputados.gob.mx/votaciones_diputados_xperiodonplxii.php?dipt=307)\n",
      "2021-05-13 14:55:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://sitllxii.diputados.gob.mx/votaciones_por_pernplxii.php?iddipt=307&pert=13> (referer: http://sitllxii.diputados.gob.mx/votaciones_diputados_xperiodonplxii.php?dipt=307)\n",
      "2021-05-13 14:55:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://sitllxii.diputados.gob.mx/votaciones_por_pernplxii.php?iddipt=307&pert=15> (referer: http://sitllxii.diputados.gob.mx/votaciones_diputados_xperiodonplxii.php?dipt=307)\n",
      "2021-05-13 14:55:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://sitllxii.diputados.gob.mx/votaciones_por_pernplxii.php?iddipt=307&pert=5> (referer: http://sitllxii.diputados.gob.mx/votaciones_diputados_xperiodonplxii.php?dipt=307)\n",
      "2021-05-13 14:55:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://sitllxii.diputados.gob.mx/proposiciones_por_pernplxii.php?iddipt=304&pert=12> (referer: http://sitllxii.diputados.gob.mx/proposiciones_diputados_xperiodonplxii.php?dipt=304)\n",
      "2021-05-13 14:55:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://sitllxii.diputados.gob.mx/proposiciones_por_pernplxii.php?iddipt=304&pert=11> (referer: http://sitllxii.diputados.gob.mx/proposiciones_diputados_xperiodonplxii.php?dipt=304)\n",
      "2021-05-13 14:55:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://sitllxii.diputados.gob.mx/votaciones_por_pernplxii.php?iddipt=307&pert=3> (referer: http://sitllxii.diputados.gob.mx/votaciones_diputados_xperiodonplxii.php?dipt=307)\n",
      "2021-05-13 14:55:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://sitllxii.diputados.gob.mx/proposiciones_por_pernplxii.php?iddipt=304&pert=9> (referer: http://sitllxii.diputados.gob.mx/proposiciones_diputados_xperiodonplxii.php?dipt=304)\n",
      "2021-05-13 14:55:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://sitllxii.diputados.gob.mx/votaciones_por_pernplxii.php?iddipt=307&pert=7> (referer: http://sitllxii.diputados.gob.mx/votaciones_diputados_xperiodonplxii.php?dipt=307)\n",
      "2021-05-13 14:55:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://sitllxii.diputados.gob.mx/proposiciones_por_pernplxii.php?iddipt=304&pert=8> (referer: http://sitllxii.diputados.gob.mx/proposiciones_diputados_xperiodonplxii.php?dipt=304)\n",
      "2021-05-13 14:55:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://sitllxii.diputados.gob.mx/proposiciones_por_pernplxii.php?iddipt=304&pert=7> (referer: http://sitllxii.diputados.gob.mx/proposiciones_diputados_xperiodonplxii.php?dipt=304)\n",
      "2021-05-13 14:55:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://sitllxii.diputados.gob.mx/proposiciones_por_pernplxii.php?iddipt=304&pert=6> (referer: http://sitllxii.diputados.gob.mx/proposiciones_diputados_xperiodonplxii.php?dipt=304)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-13 14:55:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://sitllxii.diputados.gob.mx/votaciones_por_pernplxii.php?iddipt=307&pert=14> (referer: http://sitllxii.diputados.gob.mx/votaciones_diputados_xperiodonplxii.php?dipt=307)\n",
      "2021-05-13 14:55:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://sitllxii.diputados.gob.mx/iniciativas_por_pernplxii.php?iddipt=302&pert=9> (referer: http://sitllxii.diputados.gob.mx/iniciativas_diputados_xperiodonplxii.php?dipt=302)\n",
      "2021-05-13 14:55:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://sitllxii.diputados.gob.mx/proposiciones_por_pernplxii.php?iddipt=304&pert=5> (referer: http://sitllxii.diputados.gob.mx/proposiciones_diputados_xperiodonplxii.php?dipt=304)\n",
      "2021-05-13 14:55:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://sitllxii.diputados.gob.mx/proposiciones_por_pernplxii.php?iddipt=302&pert=8> (referer: http://sitllxii.diputados.gob.mx/proposiciones_diputados_xperiodonplxii.php?dipt=302)\n",
      "2021-05-13 14:55:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://sitllxii.diputados.gob.mx/proposiciones_por_pernplxii.php?iddipt=302&pert=7> (referer: http://sitllxii.diputados.gob.mx/proposiciones_diputados_xperiodonplxii.php?dipt=302)\n",
      "2021-05-13 14:55:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://sitllxii.diputados.gob.mx/proposiciones_por_pernplxii.php?iddipt=302&pert=4> (referer: http://sitllxii.diputados.gob.mx/proposiciones_diputados_xperiodonplxii.php?dipt=302)\n",
      "2021-05-13 14:55:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://sitllxii.diputados.gob.mx/proposiciones_por_pernplxii.php?iddipt=302&pert=3> (referer: http://sitllxii.diputados.gob.mx/proposiciones_diputados_xperiodonplxii.php?dipt=302)\n",
      "2021-05-13 14:55:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://sitllxii.diputados.gob.mx/proposiciones_por_pernplxii.php?iddipt=302&pert=11> (referer: http://sitllxii.diputados.gob.mx/proposiciones_diputados_xperiodonplxii.php?dipt=302)\n",
      "2021-05-13 14:55:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://sitllxii.diputados.gob.mx/proposiciones_por_pernplxii.php?iddipt=302&pert=1> (referer: http://sitllxii.diputados.gob.mx/proposiciones_diputados_xperiodonplxii.php?dipt=302)\n",
      "2021-05-13 14:55:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://sitllxii.diputados.gob.mx/proposiciones_por_pernplxii.php?iddipt=302&pert=5> (referer: http://sitllxii.diputados.gob.mx/proposiciones_diputados_xperiodonplxii.php?dipt=302)\n",
      "2021-05-13 14:55:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://sitllxii.diputados.gob.mx/votaciones_por_pernplxii.php?iddipt=302&pert=18> (referer: http://sitllxii.diputados.gob.mx/votaciones_diputados_xperiodonplxii.php?dipt=302)\n",
      "2021-05-13 14:55:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://sitllxii.diputados.gob.mx/votaciones_por_pernplxii.php?iddipt=302&pert=11> (referer: http://sitllxii.diputados.gob.mx/votaciones_diputados_xperiodonplxii.php?dipt=302)\n",
      "2021-05-13 14:55:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://sitllxii.diputados.gob.mx/votaciones_por_pernplxii.php?iddipt=302&pert=17> (referer: http://sitllxii.diputados.gob.mx/votaciones_diputados_xperiodonplxii.php?dipt=302)\n",
      "2021-05-13 14:55:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://sitllxii.diputados.gob.mx/votaciones_por_pernplxii.php?iddipt=307&pert=1> (referer: http://sitllxii.diputados.gob.mx/votaciones_diputados_xperiodonplxii.php?dipt=307)\n",
      "2021-05-13 14:55:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://sitllxii.diputados.gob.mx/proposiciones_por_pernplxii.php?iddipt=302&pert=9> (referer: http://sitllxii.diputados.gob.mx/proposiciones_diputados_xperiodonplxii.php?dipt=302)\n",
      "2021-05-13 14:55:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://sitllxii.diputados.gob.mx/votaciones_por_pernplxii.php?iddipt=302&pert=16> (referer: http://sitllxii.diputados.gob.mx/votaciones_diputados_xperiodonplxii.php?dipt=302)\n",
      "2021-05-13 14:55:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://sitllxii.diputados.gob.mx/votaciones_por_pernplxii.php?iddipt=302&pert=5> (referer: http://sitllxii.diputados.gob.mx/votaciones_diputados_xperiodonplxii.php?dipt=302)\n",
      "2021-05-13 14:55:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://sitllxii.diputados.gob.mx/votaciones_por_pernplxii.php?iddipt=302&pert=15> (referer: http://sitllxii.diputados.gob.mx/votaciones_diputados_xperiodonplxii.php?dipt=302)\n",
      "2021-05-13 14:55:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://sitllxii.diputados.gob.mx/votaciones_por_pernplxii.php?iddipt=302&pert=9> (referer: http://sitllxii.diputados.gob.mx/votaciones_diputados_xperiodonplxii.php?dipt=302)\n",
      "2021-05-13 14:55:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://sitllxii.diputados.gob.mx/votaciones_por_pernplxii.php?iddipt=302&pert=7> (referer: http://sitllxii.diputados.gob.mx/votaciones_diputados_xperiodonplxii.php?dipt=302)\n",
      "2021-05-13 14:55:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://sitllxii.diputados.gob.mx/votaciones_por_pernplxii.php?iddipt=302&pert=14> (referer: http://sitllxii.diputados.gob.mx/votaciones_diputados_xperiodonplxii.php?dipt=302)\n",
      "2021-05-13 14:55:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://sitllxii.diputados.gob.mx/votaciones_por_pernplxii.php?iddipt=302&pert=13> (referer: http://sitllxii.diputados.gob.mx/votaciones_diputados_xperiodonplxii.php?dipt=302)\n",
      "2021-05-13 14:55:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://sitllxii.diputados.gob.mx/votaciones_por_pernplxii.php?iddipt=302&pert=1> (referer: http://sitllxii.diputados.gob.mx/votaciones_diputados_xperiodonplxii.php?dipt=302)\n",
      "2021-05-13 14:55:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://sitllxii.diputados.gob.mx/iniciativas_por_pernplxii.php?iddipt=302&pert=7> (referer: http://sitllxii.diputados.gob.mx/iniciativas_diputados_xperiodonplxii.php?dipt=302)\n",
      "2021-05-13 14:55:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://sitllxii.diputados.gob.mx/iniciativas_por_pernplxii.php?iddipt=302&pert=5> (referer: http://sitllxii.diputados.gob.mx/iniciativas_diputados_xperiodonplxii.php?dipt=302)\n",
      "2021-05-13 14:55:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://sitllxii.diputados.gob.mx/iniciativas_por_pernplxii.php?iddipt=302&pert=4> (referer: http://sitllxii.diputados.gob.mx/iniciativas_diputados_xperiodonplxii.php?dipt=302)\n",
      "2021-05-13 14:55:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://sitllxii.diputados.gob.mx/iniciativas_por_pernplxii.php?iddipt=302&pert=3> (referer: http://sitllxii.diputados.gob.mx/iniciativas_diputados_xperiodonplxii.php?dipt=302)\n",
      "2021-05-13 14:55:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://sitllxii.diputados.gob.mx/votaciones_por_pernplxii.php?iddipt=302&pert=3> (referer: http://sitllxii.diputados.gob.mx/votaciones_diputados_xperiodonplxii.php?dipt=302)\n",
      "2021-05-13 14:55:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://sitllxii.diputados.gob.mx/iniciativas_por_pernplxii.php?iddipt=316&pert=7> (referer: http://sitllxii.diputados.gob.mx/iniciativas_diputados_xperiodonplxii.php?dipt=316)\n",
      "2021-05-13 14:55:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://sitllxii.diputados.gob.mx/proposiciones_por_pernplxii.php?iddipt=304&pert=1> (referer: http://sitllxii.diputados.gob.mx/proposiciones_diputados_xperiodonplxii.php?dipt=304)\n",
      "2021-05-13 14:55:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://sitllxii.diputados.gob.mx/iniciativas_por_pernplxii.php?iddipt=316&pert=11> (referer: http://sitllxii.diputados.gob.mx/iniciativas_diputados_xperiodonplxii.php?dipt=316)\n",
      "2021-05-13 14:55:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://sitllxii.diputados.gob.mx/iniciativas_por_pernplxii.php?iddipt=316&pert=10> (referer: http://sitllxii.diputados.gob.mx/iniciativas_diputados_xperiodonplxii.php?dipt=316)\n",
      "2021-05-13 14:55:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://sitllxii.diputados.gob.mx/iniciativas_por_pernplxii.php?iddipt=316&pert=9> (referer: http://sitllxii.diputados.gob.mx/iniciativas_diputados_xperiodonplxii.php?dipt=316)\n",
      "2021-05-13 14:55:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://sitllxii.diputados.gob.mx/iniciativas_por_pernplxii.php?iddipt=316&pert=8> (referer: http://sitllxii.diputados.gob.mx/iniciativas_diputados_xperiodonplxii.php?dipt=316)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-13 14:56:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://sitllxii.diputados.gob.mx/proposiciones_por_pernplxii.php?iddipt=304&pert=4> (referer: http://sitllxii.diputados.gob.mx/proposiciones_diputados_xperiodonplxii.php?dipt=304)\n",
      "2021-05-13 14:56:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://sitllxii.diputados.gob.mx/iniciativas_por_pernplxii.php?iddipt=302&pert=1> (referer: http://sitllxii.diputados.gob.mx/iniciativas_diputados_xperiodonplxii.php?dipt=302)\n",
      "2021-05-13 14:56:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://sitllxii.diputados.gob.mx/iniciativas_por_pernplxii.php?iddipt=316&pert=5> (referer: http://sitllxii.diputados.gob.mx/iniciativas_diputados_xperiodonplxii.php?dipt=316)\n",
      "2021-05-13 14:56:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://sitllxii.diputados.gob.mx/proposiciones_por_pernplxii.php?iddipt=307&pert=8> (referer: http://sitllxii.diputados.gob.mx/proposiciones_diputados_xperiodonplxii.php?dipt=307)\n",
      "2021-05-13 14:56:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://sitllxii.diputados.gob.mx/proposiciones_por_pernplxii.php?iddipt=307&pert=4> (referer: http://sitllxii.diputados.gob.mx/proposiciones_diputados_xperiodonplxii.php?dipt=307)\n",
      "2021-05-13 14:56:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://sitllxii.diputados.gob.mx/iniciativas_por_pernplxii.php?iddipt=316&pert=3> (referer: http://sitllxii.diputados.gob.mx/iniciativas_diputados_xperiodonplxii.php?dipt=316)\n",
      "2021-05-13 14:56:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://sitllxii.diputados.gob.mx/iniciativas_por_pernplxii.php?iddipt=316&pert=1> (referer: http://sitllxii.diputados.gob.mx/iniciativas_diputados_xperiodonplxii.php?dipt=316)\n",
      "2021-05-13 14:56:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://sitllxii.diputados.gob.mx/proposiciones_por_pernplxii.php?iddipt=307&pert=12> (referer: http://sitllxii.diputados.gob.mx/proposiciones_diputados_xperiodonplxii.php?dipt=307)\n",
      "2021-05-13 14:56:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://sitllxii.diputados.gob.mx/proposiciones_por_pernplxii.php?iddipt=307&pert=9> (referer: http://sitllxii.diputados.gob.mx/proposiciones_diputados_xperiodonplxii.php?dipt=307)\n",
      "2021-05-13 14:56:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://sitllxii.diputados.gob.mx/proposiciones_por_pernplxii.php?iddipt=307&pert=11> (referer: http://sitllxii.diputados.gob.mx/proposiciones_diputados_xperiodonplxii.php?dipt=307)\n",
      "2021-05-13 14:56:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://sitllxii.diputados.gob.mx/proposiciones_por_pernplxii.php?iddipt=307&pert=3> (referer: http://sitllxii.diputados.gob.mx/proposiciones_diputados_xperiodonplxii.php?dipt=307)\n",
      "2021-05-13 14:56:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://sitllxii.diputados.gob.mx/proposiciones_por_pernplxii.php?iddipt=307&pert=1> (referer: http://sitllxii.diputados.gob.mx/proposiciones_diputados_xperiodonplxii.php?dipt=307)\n",
      "2021-05-13 14:56:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://sitllxii.diputados.gob.mx/votaciones_por_pernplxii.php?iddipt=304&pert=17> (referer: http://sitllxii.diputados.gob.mx/votaciones_diputados_xperiodonplxii.php?dipt=304)\n",
      "2021-05-13 14:56:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://sitllxii.diputados.gob.mx/votaciones_por_pernplxii.php?iddipt=304&pert=15> (referer: http://sitllxii.diputados.gob.mx/votaciones_diputados_xperiodonplxii.php?dipt=304)\n",
      "2021-05-13 14:56:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://sitllxii.diputados.gob.mx/votaciones_por_pernplxii.php?iddipt=304&pert=16> (referer: http://sitllxii.diputados.gob.mx/votaciones_diputados_xperiodonplxii.php?dipt=304)\n",
      "2021-05-13 14:56:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://sitllxii.diputados.gob.mx/votaciones_por_pernplxii.php?iddipt=304&pert=18> (referer: http://sitllxii.diputados.gob.mx/votaciones_diputados_xperiodonplxii.php?dipt=304)\n",
      "2021-05-13 14:56:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://sitllxii.diputados.gob.mx/votaciones_por_pernplxii.php?iddipt=304&pert=14> (referer: http://sitllxii.diputados.gob.mx/votaciones_diputados_xperiodonplxii.php?dipt=304)\n",
      "2021-05-13 14:56:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://sitllxii.diputados.gob.mx/votaciones_por_pernplxii.php?iddipt=304&pert=13> (referer: http://sitllxii.diputados.gob.mx/votaciones_diputados_xperiodonplxii.php?dipt=304)\n",
      "2021-05-13 14:56:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://sitllxii.diputados.gob.mx/votaciones_por_pernplxii.php?iddipt=304&pert=9> (referer: http://sitllxii.diputados.gob.mx/votaciones_diputados_xperiodonplxii.php?dipt=304)\n",
      "2021-05-13 14:56:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://sitllxii.diputados.gob.mx/votaciones_por_pernplxii.php?iddipt=304&pert=7> (referer: http://sitllxii.diputados.gob.mx/votaciones_diputados_xperiodonplxii.php?dipt=304)\n",
      "2021-05-13 14:56:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://sitllxii.diputados.gob.mx/votaciones_por_pernplxii.php?iddipt=304&pert=1> (referer: http://sitllxii.diputados.gob.mx/votaciones_diputados_xperiodonplxii.php?dipt=304)\n",
      "2021-05-13 14:56:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://sitllxii.diputados.gob.mx/votaciones_por_pernplxii.php?iddipt=304&pert=3> (referer: http://sitllxii.diputados.gob.mx/votaciones_diputados_xperiodonplxii.php?dipt=304)\n",
      "2021-05-13 14:56:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://sitllxii.diputados.gob.mx/votaciones_por_pernplxii.php?iddipt=304&pert=5> (referer: http://sitllxii.diputados.gob.mx/votaciones_diputados_xperiodonplxii.php?dipt=304)\n",
      "2021-05-13 14:56:09 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2021-05-13 14:56:09 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 54271,\n",
      " 'downloader/request_count': 119,\n",
      " 'downloader/request_method_count/GET': 119,\n",
      " 'downloader/response_bytes': 2406526,\n",
      " 'downloader/response_count': 119,\n",
      " 'downloader/response_status_count/200': 119,\n",
      " 'elapsed_time_seconds': 38.633946,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2021, 5, 13, 19, 56, 9, 10879),\n",
      " 'log_count/DEBUG': 119,\n",
      " 'log_count/INFO': 10,\n",
      " 'request_depth_max': 2,\n",
      " 'response_received_count': 119,\n",
      " 'scheduler/dequeued': 119,\n",
      " 'scheduler/dequeued/memory': 119,\n",
      " 'scheduler/enqueued': 119,\n",
      " 'scheduler/enqueued/memory': 119,\n",
      " 'start_time': datetime.datetime(2021, 5, 13, 19, 55, 30, 376933)}\n",
      "2021-05-13 14:56:09 [scrapy.core.engine] INFO: Spider closed (finished)\n"
     ]
    }
   ],
   "source": [
    "dipus={}\n",
    "por_votaciones = {}\n",
    "diccionario_final={}\n",
    "dic_proposiciones = {}\n",
    "dic_iniciativas = {}\n",
    "dic_experiencia_lista = {}\n",
    "dic_experiencia_texto = {}\n",
    "dic_comisiones = {}\n",
    "urlDipu = \"http://sitllxii.diputados.gob.mx/\"\n",
    "urlCurr = \"http://sitllxii.diputados.gob.mx/curricula.php?dipt=\"\n",
    "\n",
    "por_votaciones = {}\n",
    "\n",
    "terminaciones = []\n",
    "\n",
    "for i in range(0,5):\n",
    "    for j in range(0,10):\n",
    "        for k in range(0,10):\n",
    "            terminaciones.append(str(i)+str(j)+str(k))\n",
    "terminaciones.append(str(500))\n",
    "terminaciones.pop(0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Run the Spider\n",
    "process = CrawlerProcess()\n",
    "process.crawl(Diputados)\n",
    "process.start()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creación de la base de datos\n",
    "Primero procesamos toda la información para llenar *diccionario_final*. Los 3 diccionarios obtenidos se guardan en 3 archivos ***json*** por separado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "diccionario_final = {}\n",
    "for key, value in dipus.items():\n",
    "    legislador= obtieneExp(key,dic_experiencia_lista[key],dic_experiencia_texto[key],dic_comisiones[key], dic_iniciativas[key],dic_proposiciones[key],dipus.get(key,{}))\n",
    "    diccionario_final[key] = legislador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('BaseCurricula62.json', 'a') as f:\n",
    "            json.dump(diccionario_final, f, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('PerfilesBasicos62.json', 'a') as f:\n",
    "            json.dump(dipus, f, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('BaseVotaciones62.json', 'a') as f:\n",
    "            json.dump(por_votaciones, f, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De manera similar, si así se desea, los diccionarios se pueden convertir a lista de diccionarios y guardarlos en esa estructura."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list_perfiles_basicos = [value for value in dipus.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list_of_votos = [value for value in por_votaciones.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list_legisladores = [value for value in diccionario_final.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('PerfilesBasicos_FormatoLista.json', 'a') as f:\n",
    "#            json.dump(list_perfiles_basicos, f, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('Curricula_FormatoLista.json', 'a') as f:\n",
    "#            json.dump(list_legisladores, f, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('Votaciones_FormatoLista.json', 'a') as f:\n",
    "#            json.dump(list_of_votos, f, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizando los datos\n",
    "Esta sección sirve meramente como apoyo visual. Requiere que en la última sección los diccionarios *dipus*, *por_votaciones* y *diccionario_final* se pasen a estructura lista de diccionarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizamos en formato Dataframe los perfiles básicos\n",
    "perfil_legislador = pd.DataFrame(list_perfiles_basicos)\n",
    "#perfil_legislador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizamos en formato Dataframe las votaciones\n",
    "perfil_votos = pd.DataFrame(list_of_votos)\n",
    "#perfil_votos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En este corto apartado, se selecciona arbitrariamente un diputado en específico y se obtiene el nombre de cada una de\n",
    "# las tablas de la cual se tiene información del diputado seleccionado\n",
    "\n",
    "diputadoX=list_legisladores[2] # Seleccionamos un diputado\n",
    "\n",
    "lista_tablas=[]\n",
    "for key in diputadoX:\n",
    "    print(key)\n",
    "    df = pd.DataFrame(diputadoX[key])\n",
    "    lista_tablas.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Con base en la selección del diputado, se puede consultar cada una de las tablas disponibles\n",
    "\n",
    "df=lista_tablas[3] # Seleccionamos la tabla que deseamos visualizar"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
